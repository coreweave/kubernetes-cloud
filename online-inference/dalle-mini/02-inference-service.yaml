apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  #name: dalle-mini
  name: dalle-mega
spec:
  predictor:
    containerConcurrency: 1
    minReplicas: 1
    maxReplicas: 1 
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: gpu.nvidia.com/class
              operator: In
              values:
              - RTX_A6000
              #- A100_PCIE_80GB
            - key: topology.kubernetes.io/region
              operator: In
              values:
              - ORD1 
    containers:
      - name: kserve-container
        image: tweldoncw/dalle-mini:3
        command:
          - "python3"
          - "/app/service.py"
        env:
          - name: MODEL_ID
            value: "dalle-mini/dalle-mega"
            #value: "dalle-mini/dalle-mini"
          - name: MODEL_CACHE
            value: "/mnt/models"
          - name: STORAGE_URI # Kserve mounts the PVC at /mnt/pvc/
            value: pvc://dalle-mini-model-cache/
        resources:
          requests:
            cpu: 6
            memory: 48Gi
            nvidia.com/gpu: 1
          limits:
            cpu: 6
            memory: 48Gi
            nvidia.com/gpu: 1
