apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  labels:
    qos.coreweave.cloud/latency: low
  name: sentiment
spec:
  predictor:
    maxReplicas: 10
    minReplicas: 0
    containerConcurrency: 1
    containers:
    - name: kfserving-container
      image: coreweave/fastai-sentiment:4
      env:
      - name: STORAGE_URI
        value: pvc://model-storage/sentiment
      resources:
        limits:
          cpu: "3"
          memory: 8Gi
          nvidia.com/gpu: "1"
        requests:
          cpu: "1"
          memory: 6Gi
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: gpu.nvidia.com/class
              operator: In
              values:
              - Tesla_V100
