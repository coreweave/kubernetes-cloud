apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: vllm-inference-service
  annotations:
    networking.knative.dev/ingress-class: kourier.ingress.networking.knative.dev
  labels:
    knative.coreweave.cloud/ingress: kourier.ingress.networking.knative.dev
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "1"
        autoscaling.knative.dev/maxScale: "1"
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: gpu.nvidia.com/class
                operator: In
                values:
                - RTX_A5000
              - key: topology.kubernetes.io/region
                operator: In
                values:
                - ORD1
      containers:
      - name: kfserving-container
        image: rtalaricw/vllm:0.1
        command:
          - "/bin/sh"
          - "-c"
          - |
            python -m vllm.entrypoints.openai.api_server \
              --model EleutherAI/pythia-70m \
              --model-loader-extra-config '{"tensorizer_uri": "s3://model-store/vllm/EleutherAI/pythia-70m/vllm/model.tensors"}' \
              --load-format tensorizer \
              --port 80
        env:
        - name: S3_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: s3-credentials
              key: access_key
        - name: S3_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: s3-credentials
              key: secret_key
        - name: S3_ENDPOINT_URL
          valueFrom:
            secretKeyRef:
              name: s3-credentials
              key: host_url
        ports:
        - protocol: TCP
          containerPort: 80
        livenessProbe:
          httpGet:
            path: /v1/models
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 30
        resources:
          requests:
            cpu: 4
            memory: 16Gi
            nvidia.com/gpu: 1
          limits:
            cpu: 4
            memory: 16Gi
            nvidia.com/gpu: 1
