apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  name: bloom-175b
spec:
  predictor:
    minReplicas: 1
    maxReplicas: 1 
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: gpu.nvidia.com/class
              operator: In
              values:
              - A100_PCIE_80GB
            - key: topology.kubernetes.io/region
              operator: In
              values:
              - ORD1 
    containers:
      - name: kserve-container
        image: tweldoncw/bloom-175b:3dd76b0
        command:
          - "python3"
          - "/workspace/bloom.py"
        env:
          # The following values are defaults which may be changed as needed
          - name: MODEL_PATH
            value: "/mnt/pvc/bloom" 
          - name: STORAGE_URI # Kserve mounts the PVC at /mnt/pvc/
            value: pvc://model-cache/
          - name: MODEL_DOWNLOAD_TIMEOUT
            value: "3600"
          # The following values are defaults which may be changed as needed here, as well in each predictor request. 
          - name: MIN_LENGTH
            value: "1"
          - name: MAX_LENGTH
            value: "40"
          - name: TEMPERATURE
            value: "1.0"
          - name: TOP_K
            value: "50"
          - name: TOP_P
            value: "1.0"
          - name: REPETITION_PENALTY
            value: "1.125"
        resources:
          requests:
            cpu: 12
            memory: 64Gi
            nvidia.com/gpu: 8
          limits:
            cpu: 12
            memory: 64Gi
            nvidia.com/gpu: 8
