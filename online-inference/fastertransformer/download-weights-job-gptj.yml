apiVersion: batch/v1
kind: Job
metadata:
  name: gptj-download
spec:
  template:
    spec:
      containers:
      - name: gptj-model-downloader
        image: nvcr.io/nvidia/tritonserver:22.05-py3
        imagePullPolicy: IfNotPresent
        command: 
        - /bin/sh
        - -c
        - |
          cd /mnt/pvc;
          mkdir -p /mnt/pvc/gptj-store;
          apt-get update && \
          apt-get install -y --no-install-recommends \
          zip unzip wget git python3.8 python3-pip && \ 
          python3-dev rapidjson-dev && \
          apt-get clean && \
          rm -rf /var/lib/apt/lists/*;
          pip3 install torch==1.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html;
          pip3 install --extra-index-url https://pypi.ngc.nvidia.com regex fire tritonclient[all];
          pip3 install --upgrade jax jaxlib;
          git clone https://github.com/NVIDIA/FasterTransformer.git; 
          wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json -P models; 
          wget https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt -P models;
          wget https://mystic.the-eye.eu/public/AI/GPT-J-6B/step_383500_slim.tar.gz;
          tar -xzvf step_383500_slim.tar.gz -C /mnt/pvc/gptj-store/models;
          mkdir /mnt/pvc/gptj-store/triton-model-store/fastertransformer/1 -p; 
          python3 /mnt/pvc/gptj-store/FasterTransformer/examples/pytorch/gptj/utils/gptj_ckpt_convert.py --output-dir /mnt/pvc/gptj-store/triton-model-store/fastertransformer/1 --ckpt-dir /mnt/pvc/gptj-store/models/step_383500/ --n-inference-gpus 1;
          mv /mnt/pvc/gptj-store/triton-model-store/fastertransformer/1/1-gpu/* /mnt/pvc/gptj-store/triton-model-store/fastertransformer/1/;
          touch /mnt/pvc/gptj-store/triton-model-store/fastertransformer/config.pbtxt
          echo '# Copyright (c) 2022, NVIDIA CORPORATION. All rights reserved.
          # Redistribution and use in source and binary forms, with or without
          # modification, are permitted provided that the following conditions
          # are met:
          #  * Redistributions of source code must retain the above copyright
          #    notice, this list of conditions and the following disclaimer.
          #  * Redistributions in binary form must reproduce the above copyright
          #    notice, this list of conditions and the following disclaimer in the
          #    documentation and/or other materials provided with the distribution.
          #  * Neither the name of NVIDIA CORPORATION nor the names of its
          #    contributors may be used to endorse or promote products derived
          #    from this software without specific prior written permission.
          #
          # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS AND ANY
          # EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
          # IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
          # PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
          # CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
          # EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
          # PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
          # PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
          # OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
          # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
          # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

          name: "fastertransformer"
          backend: "fastertransformer"
          default_model_filename: "gpt-j-6b"
          max_batch_size: 1024

          model_transaction_policy {
          decoupled: False
          }

          input [
            {
              name: "input_ids"
              data_type: TYPE_UINT32
              dims: [ -1 ]
            },
            {
              name: "input_lengths"
              data_type: TYPE_UINT32
              dims: [ 1 ]
              reshape: { shape: [ ] }
            },
            {
              name: "request_output_len"
              data_type: TYPE_UINT32
              dims: [ -1 ]
            },
            {
              name: "runtime_top_k"
              data_type: TYPE_UINT32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "runtime_top_p"
              data_type: TYPE_FP32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "beam_search_diversity_rate"
              data_type: TYPE_FP32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "temperature"
              data_type: TYPE_FP32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "len_penalty"
              data_type: TYPE_FP32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "repetition_penalty"
              data_type: TYPE_FP32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "random_seed"
              data_type: TYPE_INT32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "is_return_log_probs"
              data_type: TYPE_BOOL
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "beam_width"
              data_type: TYPE_UINT32
              dims: [ 1 ]
              reshape: { shape: [ ] }
              optional: true
            },
            {
              name: "bad_words_list"
              data_type: TYPE_INT32
              dims: [ 2, -1 ]
              optional: true
            },
            {
              name: "stop_words_list"
              data_type: TYPE_INT32
              dims: [ 2, -1 ]
              optional: true
            }
          ]
          output [
            {
              name: "output_ids"
              data_type: TYPE_UINT32
              dims: [ -1, -1 ]
            },
            {
              name: "sequence_length"
              data_type: TYPE_UINT32
              dims: [ -1 ]
            },
            {
              name: "cum_log_probs"
              data_type: TYPE_FP32
              dims: [ -1 ]
            },
            {
              name: "output_log_probs"
              data_type: TYPE_FP32
              dims: [ -1, -1 ]
            }
          ]
          instance_group [
            {
              count: 1
              kind: KIND_CPU
            }
          ]
          parameters {
            key: "tensor_para_size"
            value: {
              string_value: "1"
            }
          }
          parameters {
            key: "pipeline_para_size"
            value: {
              string_value: "1"
            }
          }
          parameters {
            key: "max_seq_len"
            value: {
              string_value: "528"
            }
          }
          parameters {
            key: "is_half"
            value: {
              string_value: "1"
            }
          }
          parameters {
            key: "head_num"
            value: {
              string_value: "16"
            }
          }
          parameters {
            key: "size_per_head"
            value: {
              string_value: "256"
            }
          }
          parameters {
            key: "inter_size"
            value: {
              string_value: "16384"
            }
          }
          parameters {
            key: "vocab_size"
            value: {
              string_value: "50400"
            }
          }
          parameters {
            key: "start_id"
            value: {
              string_value: "50256"
            }
          }
          parameters {
            key: "end_id"
            value: {
              string_value: "50256"
            }
          }
          parameters {
            key: "decoder_layers"
            value: {
              string_value: "28"
            }
          }
          parameters {
            key: "model_name"
            value: {
              string_value: "gptj-6-b"
            }
          }
          parameters {
            key: "rotary_embedding"
            value: {
              string_value: "64"
            }
          }
          parameters {
            key: "model_type"
            value: {
              string_value: "GPT-J"
            }
          }
          parameters {
            key: "model_checkpoint_path"
            value: {
              string_value: "/mnt/pvc/gptj-store/triton-model-store/fastertransformer/1"
            }
          }
          parameters {
            key: "enable_custom_all_reduce"
            value: {
              string_value: "0"
            }
          }' >> /mnt/pvc/gptj-store/triton-model-store/fastertransformer/config.pbtxt
          rm -rf /mnt/pvc/gptj-store/triton-model-store/fastertransformer/1/1-gpu;
        volumeMounts:
          - name: cache
            mountPath: /mnt/pvc
        resources:
          requests:
            cpu: 2
            memory: 64Gi 
          limits:
            cpu: 2
            memory: 64Gi
      volumes:
        - name: cache
          persistentVolumeClaim:
            claimName: model-storage
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/region
                operator: In
                values: 
                - LAS1
      restartPolicy: Never
  backoffLimit: 2